{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Define the path to the shared folder\n","# Make sure you have added the shared folder as a shortcut in \"My Drive\"\n","shared_folder_path = \"/content/drive/My Drive/Dl+project\"\n","\n","# Check if the shared folder exists\n","import os\n","\n","if os.path.exists(shared_folder_path):\n","    print(f\"Shared folder found: {shared_folder_path}\")\n","    print(\"Contents of the shared folder:\")\n","    # List files in the shared folder\n","    print(os.listdir(shared_folder_path))\n","else:\n","    print(f\"Shared folder not found at {shared_folder_path}.\")\n","    print(\"Ensure you have added the shared folder as a shortcut in 'My Drive'.\")\n","\n","import os\n","import shutil\n","import cv2\n","import imghdr\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n","from tensorflow.keras.applications import VGG16, ResNet50, DenseNet121, MobileNetV2\n","from sklearn.metrics import confusion_matrix, classification_report\n","import seaborn as sns\n","from google.colab import drive\n","from tensorflow.keras.preprocessing import image\n","\n","\n","drive.mount('/content/drive')\n","\n","data_dir = \"/content/drive/My Drive/Dl+project\"\n","\n","def clean_dataset(data_dir):\n","    image_exts = ['jpeg', 'jpg', 'bmp', 'png']\n","    cleaned_images = 0\n","\n","    for image_class in os.listdir(data_dir):\n","        class_path = os.path.join(data_dir, image_class)\n","        images_to_remove = []\n","\n","        for img in os.listdir(class_path):\n","            image_path = os.path.join(class_path, img)\n","            try:\n","                img = cv2.imread(image_path)\n","                tip = imghdr.what(image_path)\n","\n","                if tip not in image_exts or img is None or img.size == 0:\n","                    images_to_remove.append(image_path)\n","            except Exception as e:\n","                print(f'Issue with image {image_path}: {e}')\n","                images_to_remove.append(image_path)\n","\n","        for invalid_image in images_to_remove:\n","            os.remove(invalid_image)\n","            cleaned_images += 1\n","\n","    print(f\"Cleaned {cleaned_images} invalid images\")\n","\n","def create_data_generator(data_dir):\n","    data_gen = ImageDataGenerator(\n","        rescale=1./255,\n","        validation_split=0.2\n","    )\n","\n","    train_generator = data_gen.flow_from_directory(\n","        data_dir,\n","        target_size=(256, 256),\n","        batch_size=32,\n","        class_mode=\"binary\",\n","        subset=\"training\"\n","    )\n","\n","    validation_generator = data_gen.flow_from_directory(\n","        data_dir,\n","        target_size=(256, 256),\n","        batch_size=32,\n","        class_mode=\"binary\",\n","        subset=\"validation\"\n","    )\n","\n","    return train_generator, validation_generator\n","\n","def create_test_data_split(data_dir):\n","    data_gen = ImageDataGenerator(rescale=1./255)\n","    test_generator = data_gen.flow_from_directory(\n","        data_dir,\n","        target_size=(256, 256),\n","        batch_size=32,\n","        class_mode=\"binary\"\n","    )\n","    return test_generator\n","\n","def create_model(model_type='VGG16', input_shape=(256, 256, 3)):\n","    if model_type == 'VGG16':\n","        base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n","    elif model_type == 'ResNet50':\n","        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n","    elif model_type == 'DenseNet121':\n","        base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=input_shape)\n","    elif model_type == 'MobileNetV2':\n","        base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n","    else:\n","        raise ValueError(\"Invalid model type\")\n","\n","    for layer in base_model.layers:\n","        layer.trainable = False\n","\n","    x = base_model.output\n","    x = GlobalAveragePooling2D()(x)\n","    x = Dense(256, activation='relu')(x)\n","    x = Dropout(0.5)(x)\n","    x = Dense(1, activation='sigmoid')(x)\n","\n","    model = Model(inputs=base_model.input, outputs=x)\n","    return model\n","\n","def train_model(train_generator, validation_generator, model_type='VGG16', epochs=50):\n","    model = create_model(model_type)\n","    model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n","\n","    callbacks = [\n","        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n","        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6),\n","        ModelCheckpoint(f'best_{model_type}_model.keras', save_best_only=True, monitor='val_accuracy')\n","    ]\n","\n","    history = model.fit(train_generator, epochs=epochs, validation_data=validation_generator, callbacks=callbacks)\n","    return model, history\n","\n","def evaluate_model(model, test_generator):\n","    test_loss, test_accuracy = model.evaluate(test_generator)\n","    print(f'\\nTest Loss: {test_loss:.4f}')\n","    print(f'Test Accuracy: {test_accuracy:.4f}')\n","\n","    y_pred = model.predict(test_generator)\n","    y_pred = (y_pred > 0.5).astype(int)\n","    y_true = test_generator.labels\n","\n","    cm = confusion_matrix(y_true, y_pred)\n","    print(\"Confusion Matrix:\")\n","    print(cm)\n","\n","    cr = classification_report(y_true, y_pred, target_names=test_generator.class_indices.keys())\n","    print(\"Classification Report:\")\n","    print(cr)\n","\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n","    plt.title('Confusion Matrix')\n","    plt.xlabel('Predicted')\n","    plt.ylabel('True')\n","    plt.show()\n","\n","clean_dataset(data_dir)\n","\n","train_generator, validation_generator = create_data_generator(data_dir)\n","test_generator = create_test_data_split(data_dir)\n","\n","models = ['VGG16', 'ResNet50', 'DenseNet121', 'MobileNetV2']\n","best_model = None\n","best_accuracy = 0\n","histories = {}\n","\n","for model_type in models:\n","    print(f\"\\nTraining {model_type} model...\")\n","    model, history = train_model(train_generator, validation_generator, model_type=model_type, epochs=50)\n","    histories[model_type] = history\n","    evaluate_model(model, test_generator)\n","\n","    test_accuracy = model.evaluate(test_generator)[1]\n","    if test_accuracy > best_accuracy:\n","        best_accuracy = test_accuracy\n","        best_model = model\n","\n","def predict_on_unseen_image(model, img_path, img_size=(256, 256)):\n","    img = image.load_img(img_path, target_size=img_size)\n","    img_array = image.img_to_array(img)\n","    img_array = np.expand_dims(img_array, axis=0)\n","    img_array = img_array / 255.0\n","\n","    prediction = model.predict(img_array)\n","    predicted_class = \"Class 1\" if prediction > 0.5 else \"Class 0\"\n","    print(f\"Predicted class: {predicted_class}\")\n","\n","\n","drive.mount('/content/drive')\n","unseen_image_path = '/content/drive/MyDrive/unseendata.jpg'\n","predict_on_unseen_image(best_model, unseen_image_path)\n","#predicting on all images wih additional data\n","import os\n","from tensorflow.keras.preprocessing import image\n","import numpy as np\n","\n","def predict_on_unseen_image_batch(model, folder_path, img_size=(256, 256), limit=100):\n","\n","    image_extensions = ['.jpeg', '.jpg', '.bmp', '.png']\n","    image_files = [f for f in os.listdir(folder_path) if any(f.endswith(ext) for ext in image_extensions)]\n","\n","    image_files = image_files[:limit]\n","\n","    predictions = []\n","\n","    for img_file in image_files:\n","        img_path = os.path.join(folder_path, img_file)\n","\n","\n","        img = image.load_img(img_path, target_size=img_size)\n","        img_array = image.img_to_array(img)\n","        img_array = np.expand_dims(img_array, axis=0)\n","        img_array = img_array / 255.0\n","\n","\n","        prediction = model.predict(img_array)\n","        predicted_class = \"Class 1\" if prediction > 0.5 else \"Class 0\"\n","\n","        predictions.append((img_file, predicted_class))\n","\n","    return predictions\n","\n","unseen_folder_path = '/content/drive/MyDrive/Dl+project1/SAD'\n","predictions = predict_on_unseen_image_batch(best_model, unseen_folder_path, limit=100)\n","\n","for img_file, predicted_class in predictions:\n","    print(f\"Image: {img_file} | Predicted Class: {predicted_class}\")\n","\n","#Predicting on max 100 images\n","import os\n","import random\n","from tensorflow.keras.preprocessing import image\n","import numpy as np\n","\n","def predict_on_unseen_image_batch_from_two_folders(model, folder_path1, folder_path2, img_size=(256, 256), limit=100):\n","\n","    image_extensions = ['.jpeg', '.jpg', '.bmp', '.png']\n","\n","    image_files1 = [f for f in os.listdir(folder_path1) if any(f.endswith(ext) for ext in image_extensions)]\n","    image_files2 = [f for f in os.listdir(folder_path2) if any(f.endswith(ext) for ext in image_extensions)]\n","\n","\n","    combined_image_files = image_files1 + image_files2\n","\n","\n","    combined_image_files = random.sample(combined_image_files, min(len(combined_image_files), limit))\n","\n","    predictions = []\n","\n","    for img_file in combined_image_files:\n","        if img_file in image_files1:\n","            img_path = os.path.join(folder_path1, img_file)\n","        else:\n","            img_path = os.path.join(folder_path2, img_file)\n","\n","\n","        img = image.load_img(img_path, target_size=img_size)\n","        img_array = image.img_to_array(img)\n","        img_array = np.expand_dims(img_array, axis=0)\n","        img_array = img_array / 255.0\n","\n","        prediction = model.predict(img_array)\n","        predicted_class = \"Class 1\" if prediction > 0.5 else \"Class 0\"\n","\n","        predictions.append((img_file, predicted_class))\n","\n","    return predictions\n","\n","unseen_folder_path1 = '/content/drive/MyDrive/Dl+project1/SAD'\n","unseen_folder_path2 = '/content/drive/MyDrive/Dl+project1/HAPPY'\n","\n","predictions = predict_on_unseen_image_batch_from_two_folders(best_model, unseen_folder_path1, unseen_folder_path2, limit=100)\n","\n","for img_file, predicted_class in predictions:\n","    print(f\"Image: {img_file} | Predicted Class: {predicted_class}\")\n","\n","#Predicting on max 100 images and plotting them\n","import os\n","import random\n","from tensorflow.keras.preprocessing import image\n","import numpy as np\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","def predict_on_unseen_image_batch_from_two_folders(model, folder_path1, folder_path2, img_size=(256, 256), limit=100):\n","    image_extensions = ['.jpeg', '.jpg', '.bmp', '.png']\n","\n","    image_files1 = [f for f in os.listdir(folder_path1) if any(f.endswith(ext) for ext in image_extensions)]\n","    image_files2 = [f for f in os.listdir(folder_path2) if any(f.endswith(ext) for ext in image_extensions)]\n","\n","    combined_image_files = image_files1 + image_files2\n","\n","\n","    combined_image_files = random.sample(combined_image_files, min(len(combined_image_files), limit))\n","\n","    predictions = []\n","    true_labels = []\n","\n","    for img_file in combined_image_files:\n","\n","        if img_file in image_files1:\n","            img_path = os.path.join(folder_path1, img_file)\n","            true_label = 1\n","        else:\n","            img_path = os.path.join(folder_path2, img_file)\n","            true_label = 0\n","\n","\n","        img = image.load_img(img_path, target_size=img_size)\n","        img_array = image.img_to_array(img)\n","        img_array = np.expand_dims(img_array, axis=0)\n","        img_array = img_array / 255.0\n","\n","\n","        prediction = model.predict(img_array)\n","        predicted_class = 1 if prediction > 0.5 else 0\n","\n","        predictions.append(predicted_class)\n","        true_labels.append(true_label)\n","\n","\n","    cm = confusion_matrix(true_labels, predictions)\n","\n","\n","    plt.figure(figsize=(6, 5))\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n","    plt.xlabel('Predicted Label')\n","    plt.ylabel('True Label')\n","    plt.title('Confusion Matrix')\n","    plt.show()\n","\n","    return predictions, cm\n","\n","unseen_folder_path1 = '/content/drive/MyDrive/Dl+project1/SAD'\n","unseen_folder_path2 = '/content/drive/MyDrive/Dl+project1/HAPPY'\n","\n","predictions, cm = predict_on_unseen_image_batch_from_two_folders(best_model, unseen_folder_path1, unseen_folder_path2, limit=100)\n","\n","\n","for img_file, predicted_class in zip(os.listdir(unseen_folder_path1)[:100], predictions):\n","    print(f\"Image: {img_file} | Predicted Class: {predicted_class}\")\n","\n","#get to know which classes mapped to 0 and 1\n","print(\"Class Indices Mapping:\", train_generator.class_indices)\n","\n","class_mapping = {v: k for k, v in train_generator.class_indices.items()}\n","print(\"Numeric Label to Class Name Mapping:\", class_mapping)\n","\n","#plot for training and printing best test accuracy model\n","plt.figure(figsize=(12, 8))\n","\n","for model_type, history in histories.items():\n","    plt.plot(history.history['accuracy'], label=f'{model_type} - Training Accuracy')\n","    plt.plot(history.history['val_accuracy'], linestyle='--', label=f'{model_type} - Validation Accuracy')\n","\n","plt.title('Model Training and Validation Accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","print(f\"\\nThe best model is {models[np.argmax([best_accuracy])]} with a test accuracy of {best_accuracy:.4f}\")\n","\n","#futher metrics\n","from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Evaluation\n","def evaluate_model(model, test_generator):\n","    test_loss, test_accuracy = model.evaluate(test_generator)\n","    print(f'\\nTest Loss: {test_loss:.4f}')\n","    print(f'Test Accuracy: {test_accuracy:.4f}')\n","\n","    # Predictions\n","    y_pred = model.predict(test_generator)\n","    y_pred = (y_pred > 0.5).astype(int)\n","    y_true = test_generator.labels\n","\n","    # Confusion Matrix\n","    cm = confusion_matrix(y_true, y_pred)\n","    print(\"Confusion Matrix:\")\n","    print(cm)\n","\n","    cr = classification_report(y_true, y_pred, target_names=test_generator.class_indices.keys())\n","    print(\"Classification Report:\")\n","    print(cr)\n","\n","    # Precision, Recall, F1-Score, and ROC-AUC\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    roc_auc = roc_auc_score(y_true, y_pred)\n","\n","    print(f'Precision: {precision:.4f}')\n","    print(f'Recall: {recall:.4f}')\n","    print(f'F1-Score: {f1:.4f}')\n","    print(f'ROC-AUC: {roc_auc:.4f}')\n","\n","    # Plot Confusion Matrix\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n","    plt.title('Confusion Matrix')\n","    plt.xlabel('Predicted')\n","    plt.ylabel('True')\n","    plt.show()\n","\n","    # Plot ROC Curve\n","    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n","    roc_auc_value = auc(fpr, tpr)\n","    plt.figure(figsize=(8, 6))\n","    plt.plot(fpr, tpr, color='b', label=f'ROC curve (area = {roc_auc_value:.2f})')\n","    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('Receiver Operating Characteristic')\n","    plt.legend(loc='lower right')\n","    plt.show()\n","\n","    # Plot Precision-Recall Curve\n","    plt.figure(figsize=(8, 6))\n","    sns.lineplot(x=fpr, y=tpr, label=\"Precision-Recall Curve\", color='g')\n","    plt.xlabel('Recall')\n","    plt.ylabel('Precision')\n","    plt.title('Precision-Recall Curve')\n","    plt.legend(loc='lower right')\n","    plt.show()\n","\n","    # Plot F1-Score vs Threshold\n","    thresholds_range = np.arange(0.0, 1.1, 0.1)\n","    f1_scores = [f1_score(y_true, (y_pred > thresh).astype(int)) for thresh in thresholds_range]\n","    plt.figure(figsize=(8, 6))\n","    plt.plot(thresholds_range, f1_scores, label='F1-Score vs Threshold', color='r')\n","    plt.xlabel('Threshold')\n","    plt.ylabel('F1-Score')\n","    plt.title('F1-Score vs Threshold')\n","    plt.legend(loc='best')\n","    plt.show()\n","\n","evaluate_model(best_model, test_generator)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MdOkqLmVw7m8","outputId":"26c02e09-1f8c-4d54-af1b-f2c15155beae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Shared folder found: /content/drive/My Drive/Dl+project\n","Contents of the shared folder:\n","['HAPPY', 'SAD']\n"]}]}]}